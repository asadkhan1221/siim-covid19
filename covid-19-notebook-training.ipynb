{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install '/kaggle/input/pydicom-conda-helper/libjpeg-turbo-2.1.0-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/libgcc-ng-9.3.0-h2828fa1_19.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/gdcm-2.8.9-py37h500ead1_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/conda-4.10.1-py37h89c1867_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/certifi-2020.12.5-py37h89c1867_1.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/openssl-1.1.1k-h7f98852_0.tar.bz2' -c conda-forge -y\n!conda install '/kaggle/input/pydicom-conda-helper/efficientnet-1.0.0-py37h06a4308_0.tar.bz2' -y\n!conda install '/kaggle/input/pydicom-conda-helper/keras-applications-1.0.8-py_1.tar.bz2' -c conda-forge -y","metadata":{"_uuid":"4fd8058b-8364-4c4f-a939-5207c155f85f","_cell_guid":"d508152d-7a4e-470d-b56b-aac2b43692b4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-25T09:23:13.113652Z","iopub.execute_input":"2021-06-25T09:23:13.114039Z","iopub.status.idle":"2021-06-25T09:24:37.95886Z","shell.execute_reply.started":"2021-06-25T09:23:13.113956Z","shell.execute_reply":"2021-06-25T09:24:37.957891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport albumentations as albu\nimport os\n#os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\nfrom tensorflow.keras.utils import to_categorical\nimport efficientnet as efn\nimport glob\nfrom tqdm import tqdm\nimport pydicom\nfrom pydicom import pixel_data_handlers\nimport numpy as np\nimport cv2\nimport pandas as pd\nimport math\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport efficientnet.tfkeras as efn\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.metrics import mean_absolute_error as mae","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:37.96061Z","iopub.execute_input":"2021-06-25T09:24:37.960955Z","iopub.status.idle":"2021-06-25T09:24:43.781787Z","shell.execute_reply.started":"2021-06-25T09:24:37.960903Z","shell.execute_reply":"2021-06-25T09:24:43.781007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"yolo_config = {\n    # Basic\n    'img_size': (608, 608, 3),\n    'anchors': [66, 90, 70, 98, 71, 104, 74, 102, 81, 103, 85, 92, 91, 103, 94, 99, 98, 97],\n    # (608, 608) with  data only for macula with 3355 images with both axis elongated\n    'strides': [8, 16, 32],\n    'xyscale': [1.2, 1.1, 1.05],\n\n    # Training\n    'iou_loss_thresh': 0.65,\n    'batch_size': 8,\n    'num_gpu': 1,\n\n    # Inference\n    'max_boxes': 100,\n    'iou_threshold': 0.5,\n    'score_threshold': 0.6,\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:43.783467Z","iopub.execute_input":"2021-06-25T09:24:43.78379Z","iopub.status.idle":"2021-06-25T09:24:43.792478Z","shell.execute_reply.started":"2021-06-25T09:24:43.783763Z","shell.execute_reply":"2021-06-25T09:24:43.791659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator(tf.keras.utils.Sequence):\n    \"\"\"\n    Data Generator for generating a batch in real-time to be fed to a model.\n    Ideally, it should work both for classification networks and segmentation/localisation networks.\n    \"\"\"\n\n    def __init__(self, list_ids, labels, return_labels=True, batch_size=32, dim=(256, 256, 3), n_classes=2,\n                 shuffle_data=True, augment_data=False, visualise=None, network_type='classification',\n                 anchors=None, max_boxes=100, train_on_cloud=False, major_revision=0,\n                 minor_revision=0, model_log_path='./', augmentations=None, use_vasculature=False,\n                 vasculature_directory=None, vasculature_extension='.png'):\n        self.list_ids = list_ids  # same as annotations line. Basically, the list of the images that we will read.\n        self.labels = labels\n        self.return_labels = return_labels\n        self.batch_size = batch_size\n        self.dim = dim  # image size\n        self.n_classes = n_classes\n        self.augment_data = augment_data\n        self.shuffle_data = shuffle_data\n        self.visualise = visualise\n        self.network_type = network_type\n        self.on_epoch_end()\n        self.anchors = np.array(yolo_config['anchors']).reshape((9, 2))  # YOLO anchors\n        self.max_boxes = max_boxes\n        self.train_on_cloud = train_on_cloud\n        self.major_revision = major_revision\n        self.minor_revision = minor_revision\n        self.model_log_path = model_log_path\n        self.valid_augmentations = augmentations\n        self.use_vasculature = use_vasculature\n        self.vasculature_directory = vasculature_directory\n        self.vascuture_extension = vasculature_extension\n\n    def on_epoch_end(self):\n        \"\"\"\n        This function will shuffle the list of images on each epoch end\n        :return:\n        \"\"\"\n        self.indices = np.arange(len(self.list_ids))\n        if self.shuffle_data:\n            np.random.shuffle(self.indices)\n\n    def __data_generation(self, list_ids_temp, list_labels_temp=None):\n        \"\"\"\n        Generates data for a single batch containing batch_size samples as X : (n_samples, *dim) and y as (n_samples,\n        num_classes) in case of classification network\n        Generates data for a single batch containing batch_size samples as X: (n_samples, *dim) and y as (n_samples,\n        max_boxes, 5) for segmentation network.\n        \"\"\"\n        if self.network_type == 'classification':\n            # Initialization\n            X = np.empty((self.batch_size, self.dim[0], self.dim[1], self.dim[2]), dtype=np.uint8)\n            y = np.empty(self.batch_size, dtype=np.uint8)\n\n            # Generate data\n            for i, ID in enumerate(list_ids_temp):\n                # Store sample\n                #X[i, ...] = cv2.resize(cv2.imread(ID, -1), self.dim[:2])\n                my_image = cv2.resize(cv2.imread(ID, -1), (self.dim[0], self.dim[1]))\n                my_shape = np.shape(my_image)\n                if len(my_shape) == 2:\n                    X[i, :,:,0] = my_image\n                    X[i, :,:,1] = X[i, :,:,0]\n                    X[i, :,:,2] = X[i, :,:,0]\n                elif len(my_shape) == 3:\n                    X[i, ...] = my_image\n\n                # Store class\n                y[i] = list_labels_temp[i]\n\n            if self.augment_data:\n                X = self.__augment_batch(X, y)\n\n            return X, to_categorical(y, num_classes=self.n_classes)\n\n        elif self.network_type == 'regression':\n            # Initialization\n            X = np.empty((self.batch_size, self.dim[0], self.dim[1], self.dim[2]), dtype=np.uint8)\n            y = np.empty(self.batch_size, dtype=np.float32)\n\n            # Generate data\n            for i, ID in enumerate(list_ids_temp):\n                # Store sample\n                X[i, ...] = cv2.resize(cv2.imread(ID, -1), self.dim[:2])\n\n                # Store class\n                y[i] = list_labels_temp[i]\n\n            if self.augment_data:\n                X = self.__augment_batch(X, y)\n\n            return X, y\n\n        elif self.network_type == 'segmentation':\n            X = np.empty((len(list_ids_temp), self.dim[0], self.dim[1], self.dim[2]), dtype=np.float32)\n            y_bbox = np.empty((len(list_ids_temp), self.max_boxes, 5), dtype=np.float32)\n\n            valid_sample = 0\n            for i, ID in enumerate(list_ids_temp):\n                valid, img_data, box_data = self.get_data(ID)\n                if not valid:\n                    X[valid_sample] = img_data\n                    y_bbox[valid_sample] = box_data\n                    valid_sample += 1\n\n            X = X[:valid_sample]\n            y_bbox = y_bbox[:valid_sample]\n\n            if self.augment_data:\n                X, y_bbox = self.__augment_batch(X, y_bbox)\n\n            y_tensor, y_true_boxes_xywh = self.preprocess_true_boxes(y_bbox, self.dim[:2], self.anchors,\n                                                                     self.n_classes)\n\n            return X, y_tensor, y_true_boxes_xywh\n\n        else:\n            raise Exception('Neither type of network selected')\n\n    def __len__(self):\n        \"\"\"Denotes the number of batches per epoch\"\"\"\n        return int(np.floor(len(self.list_ids) / self.batch_size))\n\n    def __getitem__(self, index):\n        \"\"\"Generate one batch of data\"\"\"\n\n        # Generate indexes of the batch\n        indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n\n        # Find list of IDs\n        list_ids_temp = [self.list_ids[k] for k in indices]\n\n        if self.train_on_cloud:\n            grdive_path = '/content/drive/My Drive/Yolo_Data/'\n            list_ids_temp = [(grdive_path + i.split('/')[-1]).replace('\\\\', '/') for i in list_ids_temp]\n\n        if self.network_type == 'classification':\n            list_labels_temp = [self.labels[k] for k in indices]\n            # Generate data\n            X, y = self.__data_generation(list_ids_temp, list_labels_temp)\n\n            if self.return_labels:\n                return X, y\n            else:\n                return X\n\n        elif self.network_type == 'regression':\n            list_labels_temp = [self.labels[k] for k in indices]\n            # Generate data\n            X, y = self.__data_generation(list_ids_temp, list_labels_temp)\n\n            if self.return_labels:\n                return X, y\n            else:\n                return X\n\n        elif self.network_type == 'segmentation':\n            X, y_tensor, y_bbox = self.__data_generation(list_ids_temp=list_ids_temp)\n\n            return [X, *y_tensor, y_bbox], np.zeros(len(list_ids_temp))\n\n        else:\n            raise Exception('Neither type of network selected.')\n\n    def get_data(self, annotation_line):\n        line = annotation_line.split()\n        if self.train_on_cloud:\n            # print(line[0] + ' ' + line[1])\n            img_path = line[0] + ' ' + line[1]\n        else:\n            img_path = line[0]\n\n        if self.use_vasculature:\n            img = cv2.imread(img_path, -1)\n            img_name = img_path.split('/')[-1]\n            # print(img_name)\n            img_extension = '.' + img_name.split('.')[-1]\n            # print(img_extension)\n            vascultaure_name = img_name.replace(img_extension, self.vascuture_extension)\n            # print(vascultaure_name)\n            vasculture_path = os.path.join(self.vasculature_directory, vascultaure_name)\n            # print(vasculture_path)\n            vasculture = cv2.imread(vasculture_path, -1)\n            img[:, :, 0] = vasculture\n            img = img[:, :, ::-1]\n        else:\n            #print(img_path)\n            img = cv2.imread(img_path, -1)\n            my_shape = np.shape(img)\n            if len(my_shape) < 3:\n                img = np.stack((img,) * 3, axis=-1)\n\n            if img is None:\n                print(img_path)\n            else:\n                img = img[:, :, ::-1]\n\n        ih, iw = img.shape[:2]\n        h, w, c = self.dim\n        if self.train_on_cloud:\n            boxes = np.array([np.array(list(map(float, box.split(',')))) for box in line[2:]],\n                             dtype=np.float32)  # x1y1x2y2\n        else:\n            boxes = np.array([np.array(list(map(float, box.split(',')))) for box in line[1:]],\n                             dtype=np.float32)  # x1y1x2y2\n        scale_w, scale_h = w / iw, h / ih\n        img = cv2.resize(img, (w, h))\n        image_data = np.array(img) / 255.\n\n        # correct boxes coordinates\n        box_data = np.zeros((self.max_boxes, 5))\n        if len(boxes) > 0:\n            np.random.shuffle(boxes)\n            boxes = boxes[:self.max_boxes]\n            boxes[:, [0, 2]] = boxes[:, [0, 2]] * scale_w  # + dx\n            boxes[:, [1, 3]] = boxes[:, [1, 3]] * scale_h  # + dy\n            # boxes[:, [0, 2]] = np.clip(boxes[:, [0, 2]], 0, w)\n            # boxes[:, [1, 3]] = np.clip(boxes[:, [1, 3]], 0, h)\n            box_data[:len(boxes)] = boxes\n\n        if np.isnan(image_data).any():\n            file = open(os.path.join(self.model_log_path, 'log-%i-%i.txt' % (self.major_revision, self.minor_revision)),\n                        'a+')\n            file.write('\\n')\n            file.write('NAN value encountered in image data. Sample will be discarded.')\n\n        if np.isnan(box_data).any():\n            file = open(os.path.join(self.model_log_path, 'log-%i-%i.txt' % (self.major_revision, self.minor_revision)),\n                        'a+')\n            file.write('\\n')\n            file.write('NAN value encountered in annotation data. Sample will be discarded.')\n\n        return (np.isnan(image_data).any() or np.isnan(box_data).any()), \\\n               image_data, box_data\n        #return (np.isnan(image_data).any() or np.isnan(box_data).any()), \\\n        #       np.stack((image_data,)*3, axis=-1), box_data\n\n    def __random_transform(self, img, annotation):\n        \"\"\"\n        We generate the augmentations that can be applied to a set of images in a dataset\n        The valid_augmentations list depends on the data that is being supplied.\n        \"\"\"\n        if self.network_type == 'classification':\n\n            composition = albu.Compose(transforms=self.valid_augmentations[:-1], p=self.valid_augmentations[-1])\n\n            transformed_data = composition(image=img)\n\n            if self.visualise:\n                temp_image = np.float32(transformed_data['image'])\n                img = np.float32(img)\n                horizontally_stacked = np.hstack((img, temp_image))\n                cv2.imshow('Transformed Image', np.uint8(horizontally_stacked))\n                cv2.waitKey()\n\n            return transformed_data['image']\n\n        elif self.network_type == 'regression':\n            composition = albu.Compose(transforms=self.valid_augmentations[:-1], p=self.valid_augmentations[-1])\n\n            transformed_data = composition(image=img)\n\n            if self.visualise:\n                temp_image = np.float32(transformed_data['image'])\n                img = np.float32(img)\n                horizontally_stacked = np.hstack((img, temp_image))\n                cv2.imshow('Transformed Image', np.uint8(horizontally_stacked))\n                cv2.waitKey()\n\n            return transformed_data['image']\n\n\n        elif self.network_type == 'segmentation':\n\n            temp, class_labels = [], []\n            for i in range(np.shape(annotation)[0]):\n                if sum(annotation[i, ...]) > 0:\n                    temp.append(list(annotation[i, ...][0:-1]))\n                    class_labels.append(self.labels[int(annotation[i, -1])])\n\n            composition = albu.Compose(transforms=self.valid_augmentations[:-1],\n                                       bbox_params=albu.BboxParams(format='pascal_voc', min_visibility=0.7,\n                                                                   label_fields=['class_labels']),\n                                       p=self.valid_augmentations[-1])\n            #print(composition.transforms)\n            transformed_data = composition(image=np.uint8(img * 255), bboxes=temp, class_labels=class_labels)\n\n            if self.visualise:\n                temp_image = np.float32(transformed_data['image'][:, :, ::-1])\n                img = np.float32(img * 255)\n\n                for i in range(len(transformed_data['class_labels'])):\n                    start_point = (int(transformed_data['bboxes'][i][0]), int(transformed_data['bboxes'][i][1]))\n                    end_point = (int(transformed_data['bboxes'][i][2]), int(transformed_data['bboxes'][i][3]))\n                    temp_image = cv2.rectangle(temp_image, start_point, end_point, (0, 0, 255), 2)\n\n                    start_point = (int(annotation[i][0]), int(annotation[i][1]))\n                    end_point = (int(annotation[i][2]), int(annotation[i][3]))\n                    img = cv2.rectangle(img, start_point, end_point, (0, 0, 255), 2)\n\n                horizontally_stacked = np.hstack((img[:, :, ::-1], temp_image))\n                cv2.imshow('Transformed Image', np.uint8(horizontally_stacked))\n                cv2.waitKey()\n\n            temp = transformed_data['bboxes']\n            class_labels = transformed_data['class_labels']\n            for i in range(len(temp)):\n                annotation[i, 0:4] = temp[i]\n                annotation[i, -1] = float(self.labels.index(class_labels[i]))\n\n            return np.array(transformed_data['image']) / 255., annotation\n\n        else:\n            raise Exception('No valid type of network selected')\n\n    def __augment_batch(self, img_batch, label_batch):\n\n        if self.network_type == 'classification':\n            for i in range(img_batch.shape[0]):\n                img_batch[i, ...] = self.__random_transform(img_batch[i, ...], self.valid_augmentations)\n            return img_batch\n\n        elif self.network_type == 'regression':\n            for i in range(img_batch.shape[0]):\n                img_batch[i, ...] = self.__random_transform(img_batch[i, ...], self.valid_augmentations)\n            return img_batch\n\n        elif self.network_type == 'segmentation':\n            for i in range(img_batch.shape[0]):\n                img_batch[i, ...], label_batch[i, ...] = self.__random_transform(img_batch[i, ...], label_batch[i, ...])\n            return img_batch, label_batch\n        else:\n            raise Exception('No valid type of network selected')\n\n    def preprocess_true_boxes(self, true_boxes, input_shape, anchors, num_classes):\n        # ToDo: Dry run this code at least once.\n        '''Preprocess true boxes to training input format\n\n        Parameters\n        ----------\n        true_boxes: array, shape=(batch_size, max boxes per img, 5)\n            Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape.\n        input_shape: array-like, hw, multiples of 32\n        anchors: array, shape=(N, 2), (9, wh)\n        num_classes: int\n\n        Returns\n        -------\n        y_true: list of array, shape like yolo_outputs, xywh are relative value\n\n        '''\n\n        num_stages = 3  # default setting for yolo, tiny yolo will be 2\n        anchor_mask = [[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n        bbox_per_grid = 3\n        true_boxes = np.array(true_boxes, dtype='float32')\n        true_boxes_abs = np.array(true_boxes, dtype='float32')\n        input_shape = np.array(input_shape, dtype='int32')\n        true_boxes_xy = (true_boxes_abs[..., 0:2] + true_boxes_abs[..., 2:4]) // 2  # (100, 2)\n        true_boxes_wh = true_boxes_abs[..., 2:4] - true_boxes_abs[..., 0:2]  # (100, 2)\n\n        # Normalize x,y,w, h, relative to img size -> (0~1)\n        true_boxes[..., 0:2] = true_boxes_xy / input_shape[::-1]  # xy\n        true_boxes[..., 2:4] = true_boxes_wh / input_shape[::-1]  # wh\n\n        bs = true_boxes.shape[0]\n        grid_sizes = [input_shape // {0: 8, 1: 16, 2: 32}[stage] for stage in range(num_stages)]\n        y_true = [np.zeros((bs,\n                            grid_sizes[s][0],\n                            grid_sizes[s][1],\n                            bbox_per_grid,\n                            5 + num_classes), dtype='float32')\n                  for s in range(num_stages)]\n        # [(?, 52, 52, 3, 5+num_classes) (?, 26, 26, 3, 5+num_classes)  (?, 13, 13, 3, 5+num_classes) ]\n        y_true_boxes_xywh = np.concatenate((true_boxes_xy, true_boxes_wh), axis=-1)\n        # Expand dim to apply broadcasting.\n        anchors = np.expand_dims(anchors, 0)  # (1, 9 , 2)\n        anchor_maxes = anchors / 2.  # (1, 9 , 2)\n        anchor_mins = -anchor_maxes  # (1, 9 , 2)\n        valid_mask = true_boxes_wh[..., 0] > 0  # (1, 100)\n\n        for batch_idx in range(bs):\n            # Discard zero rows.\n            wh = true_boxes_wh[batch_idx, valid_mask[batch_idx]]  # (# of bbox, 2)\n            num_boxes = len(wh)\n            if num_boxes == 0: continue\n            wh = np.expand_dims(wh, -2)  # (# of bbox, 1, 2)\n            box_maxes = wh / 2.  # (# of bbox, 1, 2)\n            box_mins = -box_maxes  # (# of bbox, 1, 2)\n\n            # Compute IoU between each anchors and true boxes for responsibility assignment\n            intersect_mins = np.maximum(box_mins, anchor_mins)  # (# of bbox, 9, 2)\n            intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n            intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n            intersect_area = np.prod(intersect_wh, axis=-1)  # (9,)\n            box_area = wh[..., 0] * wh[..., 1]  # (# of bbox, 1)\n            anchor_area = anchors[..., 0] * anchors[..., 1]  # (1, 9)\n            iou = intersect_area / (box_area + anchor_area - intersect_area)  # (# of bbox, 9)\n\n            # Find best anchor for each true box\n            best_anchors = np.argmax(iou, axis=-1)  # (# of bbox,)\n            for box_idx in range(num_boxes):\n                best_anchor = best_anchors[box_idx]\n                for stage in range(num_stages):\n                    if best_anchor in anchor_mask[stage]:\n                        x_offset = true_boxes[batch_idx, box_idx, 0] * grid_sizes[stage][1]\n                        y_offset = true_boxes[batch_idx, box_idx, 1] * grid_sizes[stage][0]\n                        # Grid Index\n                        grid_col = np.floor(x_offset).astype('int32')\n                        grid_row = np.floor(y_offset).astype('int32')\n                        anchor_idx = anchor_mask[stage].index(best_anchor)\n                        class_idx = true_boxes[batch_idx, box_idx, 4].astype('int32')\n                        y_true[stage][batch_idx, grid_row, grid_col, anchor_idx, :2] = true_boxes_xy[batch_idx, box_idx,\n                                                                                       :]  # abs xy\n                        y_true[stage][batch_idx, grid_row, grid_col, anchor_idx, 2:4] = true_boxes_wh[batch_idx,\n                                                                                        box_idx,\n                                                                                        :]  # abs wh\n                        y_true[stage][batch_idx, grid_row, grid_col, anchor_idx, 4] = 1  # confidence\n\n                        y_true[stage][batch_idx, grid_row, grid_col, anchor_idx, 5 + class_idx] = 1  # one-hot encoding\n\n        return y_true, y_true_boxes_xywh\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:43.794638Z","iopub.execute_input":"2021-06-25T09:24:43.795458Z","iopub.status.idle":"2021-06-25T09:24:43.871203Z","shell.execute_reply.started":"2021-06-25T09:24:43.795397Z","shell.execute_reply":"2021-06-25T09:24:43.87046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomCallback(tf.keras.callbacks.Callback):\n    def __init__(self, model, network_type, validation_data, validation_labels, major_revision, minor_revision,\n                 model_save_path,\n                 model_log_path, model_name, use_validataion_accuracy, patience=10, map_iou_threshold = 0.5,\n                 image_size = (608, 608), classes = []):\n        self.model = model\n        self.network_type = network_type\n        self.validation_data = validation_data\n        self.validation_labels = validation_labels\n        self.patience = patience\n        self.major_revision = major_revision\n        self.minor_revision = minor_revision\n        self.model_save_path = model_save_path\n        self.model_log_path = model_log_path\n        self.model_name = model_name\n        self.use_validation_accuracy = use_validataion_accuracy\n        self.accuracies = []\n        self.map_iou_threshold = map_iou_threshold\n        self.image_size = image_size\n        self.my_classes = classes\n\n    def on_train_begin(self, logs=None):\n        file = open(os.path.join(self.model_log_path, 'log-%i-%i.txt' % (self.major_revision, self.minor_revision)),\n                    'a+')\n        file.write('#' * 25)\n        file.write('\\n')\n        file.write('####MODEL NAME %s\\n' % (self.model_name))\n\n    def on_epoch_end(self, epoch, logs={}):\n        \"\"\"\n        We will calculate the validation accuracy at the end of each epoch and then we will log that accuracy to a file.\n        :param epoch: current epoch\n        :param logs:\n        :return: None\n        \"\"\"\n        loss = logs.get('loss')\n        if loss is not None:\n            if np.isnan(loss) or np.isinf(loss):\n                print('Epoch %d: Invalid loss, terminating training' % epoch)\n                file = open(\n                    os.path.join(self.model_log_path, 'log-%i-%i.txt' % (self.major_revision, self.minor_revision)),\n                    'a+')\n                file.write('Epoch %d: Invalid loss, terminating training' % epoch)\n                self.model.stop_training = True\n\n        if self.network_type == 'classification':\n            if self.use_validation_accuracy:\n                predictions = self.model.predict(self.validation_data)\n                predictions = np.argmax(predictions, axis=1)\n\n                validation_accuracy = accuracy_score(np.argmax(self.validation_labels[0:len(predictions), :], axis=1),\n                                                     predictions, normalize=True)\n                my_confusion_matrix = confusion_matrix(np.argmax(self.validation_labels[0:len(predictions), :], axis=1),\n                                                       predictions)\n\n                # Logging to file\n                file = open(\n                    os.path.join(self.model_log_path, 'log-%i-%i.txt' % (self.major_revision, self.minor_revision)),\n                    'a+')\n                file.write('#' * 25)\n                file.write('\\n')\n                file.write('####EPOCH %i\\n' % (epoch + 1))\n                file.write('#### VALIDATION ACCURACY =%.5f \\n' % validation_accuracy)\n                file.write('####CONFUSION MATRIX####')\n                file.write('\\n')\n                file.write(str(my_confusion_matrix))\n\n                print('\\n')\n                print('#' * 25)\n                print('#### EPOCH %i' % (epoch + 1))\n                print('#### VALIDATION ACCURACY =%.5f' % validation_accuracy)\n                print('####CONFUSION MATRIX####')\n                print(str(my_confusion_matrix))\n                print('#' * 25)\n\n                self.accuracies.append(validation_accuracy)\n                x = np.asarray(self.accuracies)\n                if np.argsort(-x)[0] == (len(x) - self.patience - 1):\n                    print('#### Validation accuracy no increase for %i epochs: EARLY STOPPING' % self.patience)\n                    file.write('#### Validation accuracy no increase for %i epochs: EARLY STOPPING\\n' % self.patience)\n                    self.model.stop_training = True\n\n                if (validation_accuracy > 0.000) & (validation_accuracy >= np.nanmax(self.accuracies)):\n                    print('#### Saving new best...')\n                    file.write('#### Saving new best...\\n')\n                    self.model.save_weights(\n                        os.path.join(self.model_save_path, 'm%i-%i.h5' % (self.major_revision, self.minor_revision)))\n\n                file.close()\n\n            else:\n                # Logging to file\n                file = open(\n                    os.path.join(self.model_log_path, 'log-%i-%i.txt' % (self.major_revision, self.minor_revision)),\n                    'a+')\n                file.write('#' * 25)\n                file.write('\\n')\n                file.write('####EPOCH %i\\n' % (epoch + 1))\n                file.write('#### TRAINING ACCURACY =%.5f \\n' % logs.get('categorical_accuracy'))\n\n                self.accuracies.append(logs.get('categorical_accuracy'))\n                x = np.asarray(self.accuracies)\n                if np.argsort(-x)[0] == (len(x) - self.patience - 1):\n                    print('#### Validation accuracy no increase for %i epochs: EARLY STOPPING' % self.patience)\n                    file.write('#### Validation accuracy no increase for %i epochs: EARLY STOPPING\\n' % self.patience)\n                    self.model.stop_training = True\n\n                if (logs.get('categorical_accuracy') > 0.000) & (logs.get('categorical_accuracy') >\n                                                                 np.nanmax(self.accuracies)):\n                    print('#### Saving new best...')\n                    file.write('#### Saving new best...\\n')\n                    self.model.save_weights(\n                        os.path.join(self.model_save_path, 'm%i-%i.h5' % (self.major_revision, self.minor_revision)))\n\n                file.close()\n\n        elif self.network_type == 'regression':\n            if self.use_validation_accuracy:\n                predictions = self.model.predict(self.validation_data)[:,0]\n\n                mean_absolute_error = mae(self.validation_labels[0:len(predictions)], predictions)\n\n                # Logging to file\n                file = open(\n                    os.path.join(self.model_log_path, 'log-%i-%i.txt' % (self.major_revision, self.minor_revision)),\n                    'a+')\n                file.write('#' * 25)\n                file.write('\\n')\n                file.write('####EPOCH %i\\n' % (epoch + 1))\n                file.write('#### MEAN ABSOLUTE ERROR =%.5f \\n' % mean_absolute_error)\n\n                print('\\n')\n                print('#' * 25)\n                print('#### EPOCH %i' % (epoch + 1))\n                print('#### MEAN ABSOLUTE ERROR =%.5f' % mean_absolute_error)\n                print('#' * 25)\n\n                self.accuracies.append(mean_absolute_error)\n                x = np.asarray(self.accuracies)\n                if np.argsort(-x)[0] == (len(x) - self.patience - 1):\n                    print('#### Validation accuracy no increase for %i epochs: EARLY STOPPING' % self.patience)\n                    file.write('#### Validation accuracy no increase for %i epochs: EARLY STOPPING\\n' % self.patience)\n                    self.model.stop_training = True\n\n                if (mean_absolute_error > 0.000) & (mean_absolute_error <= np.nanmin(self.accuracies)):\n                    print('#### Saving new best...')\n                    file.write('#### Saving new best...\\n')\n                    self.model.save_weights(\n                        os.path.join(self.model_save_path, 'm%i-%i.h5' % (self.major_revision, self.minor_revision)))\n\n                file.close()\n\n            else:\n                # Logging to file\n                file = open(\n                    os.path.join(self.model_log_path, 'log-%i-%i.txt' % (self.major_revision, self.minor_revision)),\n                    'a+')\n                file.write('#' * 25)\n                file.write('\\n')\n                file.write('####EPOCH %i\\n' % (epoch + 1))\n                file.write('#### TRAINING ACCURACY =%.5f \\n' % logs.get('categorical_accuracy'))\n\n                self.accuracies.append(logs.get('mae'))\n                x = np.asarray(self.accuracies)\n                if np.argsort(-x)[0] == (len(x) - self.patience - 1):\n                    print('#### Validation accuracy no increase for %i epochs: EARLY STOPPING' % self.patience)\n                    file.write('#### Validation accuracy no increase for %i epochs: EARLY STOPPING\\n' % self.patience)\n                    self.model.stop_training = True\n\n                if (logs.get('mae') > 0.000) & (logs.get('mae') <=\n                                                                 np.nanmin(self.accuracies)):\n                    print('#### Saving new best...')\n                    file.write('#### Saving new best...\\n')\n                    self.model.save_weights(\n                        os.path.join(self.model_save_path, 'm%i-%i.h5' % (self.major_revision, self.minor_revision)))\n\n                file.close()\n\n\n\n        elif self.network_type == 'segmentation':\n            my_mean_average_precision = calculate_map(validation_samples_list = self.validation_data,\n                                                      yolo_model =WorkAround.current_model , iou_threshold=self.map_iou_threshold,\n                                                      model_image_size = self.image_size,\n                                                      model_classes = self.my_classes)\n            file = open(os.path.join(self.model_log_path, 'log-%i-%i.txt' % (self.major_revision, self.minor_revision)),\n                        'a+')\n            file.write('#' * 25)\n            file.write('\\n')\n            file.write('####EPOCH %i\\n' % (epoch + 1))\n            file.write('#### TRAINING LOSS =%.5f \\n' % logs.get('loss'))\n            file.write('#### VALIDATION LOSS =%.5f \\n' % logs.get('val_loss'))\n            file.write('#### mAP =%.5f \\n' % my_mean_average_precision)\n\n            print()\n            print('mAP at ', self.map_iou_threshold, ' is: ', my_mean_average_precision)\n            temp_monitored_value = logs.get('val_loss')\n            if not math.isnan(temp_monitored_value):\n                self.accuracies.append(temp_monitored_value)\n            else:\n                self.accuracies.append(1000000)\n\n            x = np.asarray(self.accuracies)\n            if len(x) > 1:\n                if np.argsort(x)[0] == (len(x) - self.patience - 1):\n                    print('#### Validation accuracy no increase for %i epochs: EARLY STOPPING' % self.patience)\n                    file.write('#### Validation accuracy no increase for %i epochs: EARLY STOPPING\\n' % self.patience)\n                    self.model.stop_training = True\n\n                if (temp_monitored_value > 0.000) & (temp_monitored_value < np.min(self.accuracies[:-1])):\n                    print('#### Saving new best...')\n                    file.write('#### Saving new best...\\n')\n                    WorkAround.save_inference_model(path=self.model_save_path, major_revision=self.major_revision,\n                                                    minor_revision=self.minor_revision)\n\n            file.close()\n\n        else:\n            raise Exception('No valid network type selected')\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:43.873274Z","iopub.execute_input":"2021-06-25T09:24:43.873593Z","iopub.status.idle":"2021-06-25T09:24:43.91322Z","shell.execute_reply.started":"2021-06-25T09:24:43.87356Z","shell.execute_reply":"2021-06-25T09:24:43.912332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def alternate_learning_rate(epoch):\n    \"\"\"\n        An alternate scheduler for each epoch.\n        :param epoch: current epoch\n        :return: learning rate for current epoch\n        \"\"\"\n    if epoch % 2 == 0:\n        return 1e-5\n    else:\n        return 1e-4","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:43.914594Z","iopub.execute_input":"2021-06-25T09:24:43.914971Z","iopub.status.idle":"2021-06-25T09:24:43.927209Z","shell.execute_reply.started":"2021-06-25T09:24:43.914937Z","shell.execute_reply":"2021-06-25T09:24:43.926376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cosine_annealing_scheduler(epoch):\n    \"\"\"\n        A step rate scheduler for setting the learning rate for each epoch.\n        :param epoch: current epoch\n        :return: learning rate for current epoch\n        \"\"\"\n    learning_rate_min = 1e-6\n    learning_rate_max = 1e-3\n    epochs_per_cycle = 20\n\n    return learning_rate_min + (learning_rate_max - learning_rate_min) * \\\n           (1 + math.cos(math.pi * (epoch % epochs_per_cycle) / epochs_per_cycle)) / 2\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:43.928574Z","iopub.execute_input":"2021-06-25T09:24:43.929014Z","iopub.status.idle":"2021-06-25T09:24:43.940796Z","shell.execute_reply.started":"2021-06-25T09:24:43.92898Z","shell.execute_reply":"2021-06-25T09:24:43.939996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def constant_learning_scheduler(epoch):\n    \"\"\"\n    Returns a constant learning rate for every epoch\n    :param epoch: current epoch\n    :return: learning rate\n    \"\"\"\n    return 1e-5","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:43.943581Z","iopub.execute_input":"2021-06-25T09:24:43.943964Z","iopub.status.idle":"2021-06-25T09:24:43.951884Z","shell.execute_reply.started":"2021-06-25T09:24:43.943913Z","shell.execute_reply":"2021-06-25T09:24:43.951087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def learning_rate_scheduler(epoch):\n    \"\"\"\n    For training classification models we first use a step rate scheduler for initial 50 epochs and then switch\n    to cosine annealing scheduler for the remaining epochs.\n    This has the benefit of starting the learning rate slowly and then having the benefits of a cylic scheduler.\n    :param epoch: current epoch\n    :return: learning rate\n    \"\"\"\n    if epoch < 10:\n        return 0.000001\n    elif epoch < 50:\n        return step_rate_scheduler(epoch)\n    else:\n        return cosine_annealing_scheduler(epoch)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:43.953943Z","iopub.execute_input":"2021-06-25T09:24:43.954293Z","iopub.status.idle":"2021-06-25T09:24:43.962507Z","shell.execute_reply.started":"2021-06-25T09:24:43.954259Z","shell.execute_reply":"2021-06-25T09:24:43.961726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def step_rate_scheduler(epoch):\n    \"\"\"\n    A step rate scheduler for setting the learning rate for each epoch.\n    :param epoch: current epoch\n    :return: learning rate for current epoch\n    \"\"\"\n    learning_rate_start = 1e-5\n    learning_rate_max = 1e-3\n    learning_rate_rampup_epochs = 5\n    Learning_rate_sustain_epoch = 0\n    learning_rate_step_decay = 0.75\n\n    if epoch < learning_rate_rampup_epochs:\n        lr = (learning_rate_max - learning_rate_start) / learning_rate_rampup_epochs * epoch + learning_rate_start\n    elif epoch < learning_rate_rampup_epochs + Learning_rate_sustain_epoch:\n        lr = learning_rate_max\n    else:\n        lr = learning_rate_max * \\\n             learning_rate_step_decay ** ((epoch - learning_rate_rampup_epochs - Learning_rate_sustain_epoch) // 10)\n\n    return lr","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:43.963426Z","iopub.execute_input":"2021-06-25T09:24:43.963874Z","iopub.status.idle":"2021-06-25T09:24:43.973122Z","shell.execute_reply.started":"2021-06-25T09:24:43.963839Z","shell.execute_reply":"2021-06-25T09:24:43.972334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_image_paths_and_labels(network_type, input_dir, split, read_from_folders, file_name, classes):\n    \"\"\"\n    For Classification:\n        Function to read images names with paths from multiple folders and create their labels according to\n        folder name and then store them in a readable file that is used the next time around.\n        The function first checks for a single .csv file with the name file_name that is created on the first pass.\n        If that file exists, then that file is directly loaded. If the file doesn't exist, then all the images are read.\n\n    For Segmentation:\n        Function looks for a single .txt file with the name file_name containing the paths to all the iamges and their\n        corresponding bounding boxes and labels. If no such file is found, then an exception is raised.\n        If .txt file exists, then it is read and total samples are split into training and testiong samples according\n        to the given split.\n    return: Training and testing samples names with paths and labels.\n    \"\"\"\n    my_dataframe = None\n    if network_type == 'classification':\n        image_extensions = ['.jpg', '.jpeg', '.png', '.JPG']\n        images = []\n        labels = []\n\n        if read_from_folders:\n            print('Reading image names from folders...')\n            directories = [x[0] for x in os.walk(input_dir)]\n            for directory in tqdm(directories, desc='Directories Done'):\n                for each_class in classes:\n                    if each_class in directory:\n                        files = os.listdir(directory)\n                        files = [file for file in files if\n                                 any(image_extension in file for image_extension in image_extensions)]\n                        images.extend([os.path.join(directory, file) for file in files])\n                        labels.extend([classes.index(each_class)] * len(files))\n\n            # Saving files as npz array for future reads\n            my_dict = {}\n            my_dict['id'], my_dict['label'] = images, labels\n            my_dataframe = pd.DataFrame(data=my_dict, index=None)\n            my_dataframe.to_csv(os.path.join(input_dir, file_name), sep=',', index=False)\n            unique_labels = np.unique(labels)\n            total_images = 0\n            for unique_label in unique_labels:\n                total_images += np.count_nonzero(np.where(np.array(labels) == unique_label))\n                print('Total Images of Class ' + str(unique_label + 1) + ': ',\n                      np.count_nonzero(np.where(np.array(labels) == unique_label)))\n            print('Total Images Read: ', total_images)\n\n        else:\n            path_and_label_file = os.path.exists(os.path.join(input_dir, file_name))\n\n            if path_and_label_file:\n                print('Reading the .csv file')\n\n                my_dataframe = pd.read_csv(os.path.join(input_dir, file_name), sep=',')\n                images, labels = my_dataframe['id'].to_list(), my_dataframe['label'].to_list()\n                unique_labels = np.unique(labels)\n                total_images = 0\n                for unique_label in unique_labels:\n                    total_images += np.count_nonzero(np.where(np.array(labels) == unique_label))\n                    print('Total Images of Class ' + str(unique_label + 1) + ': ',\n                          np.count_nonzero(np.where(np.array(labels) == unique_label)))\n                print('Total Images Read: ', total_images)\n\n            else:\n                print('Relevant .csv files do not exist. Data set not loaded.')\n\n\n    elif network_type == 'segmentation':\n        text_file = os.path.exists(os.path.join(input_dir, file_name))\n\n        if text_file:\n            print('Reading the .txt file')\n            my_dataframe = pd.read_csv(os.path.join(input_dir, file_name), sep='\\n', header=None)\n            print('Total Examples: ', len(my_dataframe))\n            examples = my_dataframe[0].to_list()\n\n            examples = shuffle(examples)\n\n            training, testing, training_labels, testing_labels = train_test_split(examples, [0] * len(examples),\n                                                                                  train_size=split)\n            return training, training_labels, testing, testing_labels\n\n        else:\n            raise Exception('Text file with segmentation examples does not exist')\n\n    elif network_type == 'regression':\n        path_and_label_file = os.path.exists(os.path.join(input_dir, file_name))\n\n        if path_and_label_file:\n            print('Reading the .csv file')\n\n            my_dataframe = pd.read_csv(os.path.join(input_dir, file_name), sep=',')\n            images, labels = my_dataframe['id'].to_list(), my_dataframe['label'].to_list()\n            total_images = len(images)\n            print('Total Images Read: ', total_images)\n\n        else:\n            print('Relevant .csv files do not exist. Data set not loaded.')\n\n    else:\n        raise Exception('No valid network type selected')\n\n    images, labels = shuffle(images, labels)\n\n    training, testing, training_labels, testing_labels = train_test_split(images, labels, train_size=split)\n\n    return training, training_labels, testing, testing_labels","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:43.974281Z","iopub.execute_input":"2021-06-25T09:24:43.974527Z","iopub.status.idle":"2021-06-25T09:24:43.996246Z","shell.execute_reply.started":"2021-06-25T09:24:43.974506Z","shell.execute_reply":"2021-06-25T09:24:43.995445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(os.listdir('../input/dicom-image-extractor/')))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:43.997395Z","iopub.execute_input":"2021-06-25T09:24:43.997816Z","iopub.status.idle":"2021-06-25T09:24:44.184844Z","shell.execute_reply.started":"2021-06-25T09:24:43.997709Z","shell.execute_reply":"2021-06-25T09:24:44.184065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir  './1/'\n!mkdir  './2/'\n#!mkdir  './3/'\n#!mkdir  './4/'\n!mkdir  './models/'\n!mkdir  './logs/'","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:48.109321Z","iopub.execute_input":"2021-06-25T09:24:48.109588Z","iopub.status.idle":"2021-06-25T09:24:51.91321Z","shell.execute_reply.started":"2021-06-25T09:24:48.109559Z","shell.execute_reply":"2021-06-25T09:24:51.912186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Separating SIIM train images for classification\nmy_csv = pd.read_csv('../input/siim-covid19-detection/train_study_level.csv', sep=',')\ninput_dir = '../input/dicom-image-extractor/'\noutput_dir = './'\n\nall_images = os.listdir(input_dir)\n\npossible_classes = ['1', '2', '3', '4']\n\nfor row in tqdm(range(len(my_csv))):\n    my_row = my_csv.loc[row].values.tolist()\n    image_name = my_row[0].split('_')\n\n    complete_name = [x for x in all_images if image_name[0] in x]\n    #print(complete_name)\n    #if len(complete_name) > 1:\n        #print(complete_name)\n\n        \n    for value in complete_name:\n\n        my_image = cv2.imread(os.path.join(input_dir, value), -1)\n        #print(np.shape(my_image))\n\n        #my_image = np.stack((my_image,)*3, axis=-1)\n\n        if my_row[1] == 1:\n            #print(os.path.join(output_dir, possible_classes[0], value))\n            cv2.imwrite(os.path.join(output_dir, possible_classes[0], value), my_image)\n            #print(len(os.path.join(output_dir, possible_classes[0])))\n\n        elif my_row[2] == 1:\n            cv2.imwrite(os.path.join(output_dir, possible_classes[1], value), my_image)\n            #print(len(os.path.join(output_dir, possible_classes[1])))\n\n        elif my_row[3] == 1:\n            cv2.imwrite(os.path.join(output_dir, possible_classes[1], value), my_image)\n            #print(len(os.path.join(output_dir, possible_classes[2])))\n\n        elif my_row[4] == 1:\n            cv2.imwrite(os.path.join(output_dir, possible_classes[1], value), my_image)\n            #print(len(os.path.join(output_dir, possible_classes[3])))\n\n        else:\n            pass\n\nprint('Done')","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:24:51.9148Z","iopub.execute_input":"2021-06-25T09:24:51.915149Z","iopub.status.idle":"2021-06-25T09:29:00.650995Z","shell.execute_reply.started":"2021-06-25T09:24:51.915113Z","shell.execute_reply":"2021-06-25T09:29:00.650151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(os.listdir('./1')))\nprint(len(os.listdir('./2')))\n#print(len(os.listdir('./3')))\n#print(len(os.listdir('./4')))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:29:00.653786Z","iopub.execute_input":"2021-06-25T09:29:00.654051Z","iopub.status.idle":"2021-06-25T09:29:00.666997Z","shell.execute_reply.started":"2021-06-25T09:29:00.654025Z","shell.execute_reply":"2021-06-25T09:29:00.666149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dim = (600, 600, 3)\n# Training Parameters:\nepochs, initial_epoch = 14, 0\nnetwork_type, batch_size, n_classes, model_name, build_new, patience = \"classification\", 2, 4, \"EfficientNetB7\", True, 15\nmajor_revision, minor_revision = 2, 41\nno_improvement = False","metadata":{"_uuid":"2d37d028-94de-4338-b91b-ec51c3f2e740","_cell_guid":"11d4164a-43a1-442f-b183-c9ce00861050","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-25T09:29:00.668393Z","iopub.execute_input":"2021-06-25T09:29:00.668773Z","iopub.status.idle":"2021-06-25T09:29:00.674355Z","shell.execute_reply.started":"2021-06-25T09:29:00.668734Z","shell.execute_reply":"2021-06-25T09:29:00.673299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Generator Parameters\ntrain_using_generator, shuffle_data, augment_data, return_labels, visualise = True, True, True, True, False\ntraining_testing_split = 0.9\nread_from_folder = True\n#classes = ['aortic_enlargement', 'atelectasis', 'calcification', 'cardiomegaly',\n#           'consolidation', 'ild', 'infiltration', 'lung_opacity', 'no_finding', 'nodule', 'other_lesion',\n#           'pleural_effusion', 'pleural_thickening', 'pneumothorax', 'pulmonary_fibrosis']\nclasses = ['1', '2']\nfile_name = 'image_paths_and_labels_updated.csv'","metadata":{"_uuid":"ea8de281-c971-4c31-bc91-44d102fbbb7d","_cell_guid":"69e1273c-54be-453d-8ca4-83247b9590c1","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-25T09:29:00.675779Z","iopub.execute_input":"2021-06-25T09:29:00.676154Z","iopub.status.idle":"2021-06-25T09:29:00.683126Z","shell.execute_reply.started":"2021-06-25T09:29:00.676117Z","shell.execute_reply":"2021-06-25T09:29:00.68207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = 0.25\naugmentations = [albu.Flip(p=p),albu.HorizontalFlip(p=p),albu.ShiftScaleRotate(shift_limit=(-0.1599999964237213, 0.05999999865889549),scale_limit=(-0.10000000149011612, 0.05000000074505806),rotate_limit=(-39, -7),interpolation=0, border_mode=0, value=(0, 0, 0), mask_value=None, p=p),\n                     albu.RandomBrightness(p=p), albu.Rotate(p=p, limit=90),\n                     albu.RandomContrast(limit=0.5, p=p),\n                     albu.NoOp(p=p), 0.65]\nuse_validation_data = True","metadata":{"_uuid":"3f237e8b-f886-40a9-986a-b69973e3ef9d","_cell_guid":"ad6285a3-9889-4b07-88a5-cfda9ebb1934","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-25T09:29:00.684593Z","iopub.execute_input":"2021-06-25T09:29:00.685016Z","iopub.status.idle":"2021-06-25T09:29:00.693582Z","shell.execute_reply.started":"2021-06-25T09:29:00.68498Z","shell.execute_reply":"2021-06-25T09:29:00.692435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def focal_loss(gamma=2., alpha=1.):\n    \"\"\"Implements focal loss for the deep learning model\"\"\"\n\n    gamma = float(gamma)\n    alpha = float(alpha)\n\n    def focal_loss_fixed(y_true, y_pred):\n        \"\"\"Focal loss for multi-classification\n        FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n        Notice: y_pred is probability after softmax\n        gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n        d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n        Focal Loss for Dense Object Detection\n        https://arxiv.org/abs/1708.02002\n\n        Arguments:\n            y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n            y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n\n        Keyword Arguments:\n            gamma {float} -- (default: {2.0})\n            alpha {float} -- (default: {4.0})\n\n        Returns:\n            [tensor] -- loss.\n        \"\"\"\n        epsilon = 1.e-9\n        y_true = tf.convert_to_tensor(y_true, tf.float32)\n        y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n\n        model_out = tf.add(y_pred, epsilon)\n        ce = tf.multiply(y_true, - tf.math.log(model_out))\n        weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n        fl = tf.multiply(alpha, tf.multiply(weight, ce))\n        reduced_fl = tf.reduce_max(fl, axis=1)\n        return tf.reduce_mean(reduced_fl)\n    return focal_loss_fixed","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:29:00.934026Z","iopub.execute_input":"2021-06-25T09:29:00.934272Z","iopub.status.idle":"2021-06-25T09:29:00.941367Z","shell.execute_reply.started":"2021-06-25T09:29:00.934246Z","shell.execute_reply":"2021-06-25T09:29:00.940443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dir = \"./\"\nmodel_save_path = \"./models\"\nlog_save_path = \"./logs\"","metadata":{"_uuid":"d7c7d8b9-c8d5-4080-8983-eb867f15a733","_cell_guid":"ca5ec7a5-6405-42f9-b65d-a64af3353e7e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-25T09:29:00.695987Z","iopub.execute_input":"2021-06-25T09:29:00.696236Z","iopub.status.idle":"2021-06-25T09:29:00.702853Z","shell.execute_reply.started":"2021-06-25T09:29:00.696212Z","shell.execute_reply":"2021-06-25T09:29:00.702077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Generator Parameters\ntrain_using_generator, shuffle_data, augment_data, return_labels, visualise = True, True, True, True, False\ntraining_testing_split = 0.9\nread_from_folder = True","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:29:00.705679Z","iopub.execute_input":"2021-06-25T09:29:00.705953Z","iopub.status.idle":"2021-06-25T09:29:00.712759Z","shell.execute_reply.started":"2021-06-25T09:29:00.705906Z","shell.execute_reply":"2021-06-25T09:29:00.711906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data, training_labels, testing_data, testing_labels = generate_image_paths_and_labels(network_type=network_type, input_dir=input_dir, split=training_testing_split, read_from_folders=read_from_folder, file_name=file_name, classes=classes)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:29:00.713767Z","iopub.execute_input":"2021-06-25T09:29:00.714032Z","iopub.status.idle":"2021-06-25T09:29:00.930487Z","shell.execute_reply.started":"2021-06-25T09:29:00.714007Z","shell.execute_reply":"2021-06-25T09:29:00.929509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_input_layer = tf.keras.Input(shape=input_dim)\nmy_base_model = efn.EfficientNetB7(weights='imagenet', include_top=False, input_shape=input_dim)\nx = my_base_model(my_input_layer)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\nx = tf.keras.layers.Dense(8, activation='relu', name='Dense_1', dtype='float32')(x)\nx = tf.keras.layers.Dense(n_classes, activation='softmax', name='Output', dtype='float32')(x)\nmy_model = tf.keras.Model(inputs=my_input_layer, outputs=x, name=model_name)\nmy_optimiser = tf.keras.optimizers.Adam(lr=0.00001)\n#my_model.compile(loss='categorical_crossentropy', optimizer=my_optimiser, metrics=['categorical_accuracy'])\nmy_model.compile(loss=focal_loss(), optimizer=my_optimiser,metrics=['accuracy'])\nmy_model.summary()\nmy_model.save(os.path.join('./models', 'm%i-%i_%s.h5' % (major_revision, minor_revision, 'model')))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# my_input_layer = tf.keras.Input(shape=input_dim)\n# my_base_model = efn.EfficientNetB7(weights='imagenet', include_top=False, input_shape=input_dim)\n# x = my_base_model(my_input_layer)\n# x = tf.keras.layers.GlobalAveragePooling2D()(x)\n# x = tf.keras.layers.Dense(8, activation='relu', name='Dense_1', dtype='float32')(x)\n# x = tf.keras.layers.Dense(n_classes, activation='softmax', name='Output', dtype='float32')(x)\n# my_model = tf.keras.Model(inputs=my_input_layer, outputs=x, name=model_name)\n# my_optimiser = tf.keras.optimizers.Adam(lr=0.00001)\n# my_model.compile(loss='categorical_crossentropy', optimizer=my_optimiser, metrics=['categorical_accuracy'])\n# #my_model.compile(loss=focal_loss(), optimizer=my_optimiser,metrics=['accuracy'])\n# my_model.summary()\n# my_model.save(os.path.join('./models', 'm%i-%i_%s.h5' % (major_revision, minor_revision, 'model')))","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:29:00.94323Z","iopub.execute_input":"2021-06-25T09:29:00.943612Z","iopub.status.idle":"2021-06-25T09:29:12.208697Z","shell.execute_reply.started":"2021-06-25T09:29:00.943559Z","shell.execute_reply":"2021-06-25T09:29:12.207874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generated_train_data = DataGenerator(list_ids=training_data, labels=training_labels, return_labels=return_labels, batch_size=batch_size, dim=input_dim,n_classes=n_classes, shuffle_data=shuffle_data, augment_data=augment_data,network_type=network_type, visualise=visualise,major_revision=major_revision, minor_revision=minor_revision,train_on_cloud=False,model_log_path=log_save_path,augmentations=augmentations)\n\ngenerated_validation_data = DataGenerator(list_ids=testing_data, labels=testing_labels, return_labels=False, batch_size=batch_size, dim=input_dim,n_classes=n_classes, shuffle_data=False,augment_data=False,network_type=network_type, visualise=visualise,major_revision=major_revision,minor_revision=minor_revision, model_log_path=log_save_path,augmentations=augmentations)\n\ntesting_labels = to_categorical(testing_labels, num_classes=n_classes)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:29:12.210257Z","iopub.execute_input":"2021-06-25T09:29:12.210614Z","iopub.status.idle":"2021-06-25T09:29:12.219949Z","shell.execute_reply.started":"2021-06-25T09:29:12.210566Z","shell.execute_reply":"2021-06-25T09:29:12.219081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # Creating Callbacks\nmy_custom_callback = CustomCallback(model=my_model, network_type=network_type, validation_data=generated_validation_data, validation_labels=testing_labels, major_revision=major_revision, minor_revision=minor_revision,model_save_path=model_save_path, model_log_path=log_save_path,model_name=model_name, use_validataion_accuracy=use_validation_data,patience=patience)\n\nmy_callbacks = [my_custom_callback,tf.keras.callbacks.LearningRateScheduler(alternate_learning_rate, verbose=True)]","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:29:12.221116Z","iopub.execute_input":"2021-06-25T09:29:12.221569Z","iopub.status.idle":"2021-06-25T09:29:12.34895Z","shell.execute_reply.started":"2021-06-25T09:29:12.221533Z","shell.execute_reply":"2021-06-25T09:29:12.348014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Scheduler selected: ', alternate_learning_rate)\n\nprint('Training Testing Split is: ', training_testing_split)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:29:12.352305Z","iopub.execute_input":"2021-06-25T09:29:12.352564Z","iopub.status.idle":"2021-06-25T09:29:12.365104Z","shell.execute_reply.started":"2021-06-25T09:29:12.352539Z","shell.execute_reply":"2021-06-25T09:29:12.363973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_model_history = my_model.fit(generated_train_data, epochs=epochs,initial_epoch=initial_epoch, callbacks=my_callbacks, verbose=1, max_queue_size=(1 * 1) * 64, workers=128)","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:29:12.366549Z","iopub.execute_input":"2021-06-25T09:29:12.366894Z","iopub.status.idle":"2021-06-25T09:34:46.787712Z","shell.execute_reply.started":"2021-06-25T09:29:12.36686Z","shell.execute_reply":"2021-06-25T09:34:46.786218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r './1/'\n!rm -r './2/'\n!rm -r './3/'\n!rm -r './4/'","metadata":{"execution":{"iopub.status.busy":"2021-06-25T09:36:13.240943Z","iopub.execute_input":"2021-06-25T09:36:13.2413Z","iopub.status.idle":"2021-06-25T09:36:16.247927Z","shell.execute_reply.started":"2021-06-25T09:36:13.241264Z","shell.execute_reply":"2021-06-25T09:36:16.246869Z"},"trusted":true},"execution_count":null,"outputs":[]}]}